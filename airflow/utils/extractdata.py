"""
å„ç¨®æå–è³‡æ–™åšè½‰åŒ–çš„å‡½å¼åº«
Creator: Chgwyellow

from mods import extractdata as ed
"""

import ast
import re

import numpy as np
import pandas as pd
from colorama import Fore
from utils import connectDB as connDB
from utils import date_mod as dm
from utils import gmap as gm
from utils import savedata as sd


def extract_city_district(address: str) -> tuple[str, str]:
    """å¾æ©Ÿæ§‹çš„åœ°å€å–å‡ºæ‰€åœ¨å¸‚èˆ‡å€
    æ­¤è™•reçš„patternæ˜¯è¨­å®šç‚ºå…­éƒ½åŠè½„ä¸‹å€åŸŸ

    Args:
        address (str): è¦å°‹æ‰¾çš„åœ°å€

    Returns:
        tuple[str, str]: å‰è€…è¿”å›city, å¾Œè€…è¿”å›district, å¦‚æœæ²’æœ‰å‰‡éƒ½è¿”å›None
    """

    # é€™è£¡patternç”¨å…­éƒ½çš„æ–¹å¼åšè¨­å®š
    pattern = r"(è‡ºåŒ—å¸‚|å°åŒ—å¸‚|æ–°åŒ—å¸‚|æ¡ƒåœ’å¸‚|å°ä¸­å¸‚|è‡ºä¸­å¸‚|å°å—å¸‚|è‡ºå—å¸‚|é«˜é›„å¸‚)(.*?å€)"
    match = re.search(pattern=pattern, string=address)
    if match:
        return match.group(1), match.group(2)
    return None, None


def extract_city_district_from_df(df: pd.DataFrame, address_col: str) -> pd.DataFrame:
    """å¾ DataFrame çš„åœ°å€æ¬„ä½æå–åŸå¸‚å’Œåœ°å€è³‡è¨Š

    Args:
        df (pd.DataFrame): è¦è™•ç†çš„ DataFrame
        address_col (str): åœ°å€æ¬„ä½åç¨±

    Returns:
        pd.DataFrame: æ·»åŠ  city å’Œ district æ¬„ä½å¾Œçš„ DataFrame
    """
    # ä½¿ç”¨ zip å’Œ apply æå–åŸå¸‚èˆ‡åœ°å€
    df["city"], df["district"] = zip(*df[address_col].apply(extract_city_district))

    # åªä¿ç•™æœ‰åŸå¸‚è³‡è¨Šçš„è³‡æ–™åˆ—(å…­éƒ½)
    df = df[df["city"].notna()].reset_index(drop=True)

    return df


def gdata_place_id(df: pd.DataFrame, api_key: str, save_path: str) -> pd.DataFrame:
    """
    æ¸…ç†èˆ‡è£œå…… Google å¯µç‰©æ—…é¤¨è³‡æ–™
    ä½¿ç”¨å‰è«‹ç¢ºèªå‚³å…¥çš„dfæ¬„ä½åªæœ‰name, address, cityå’Œdistrict
    ------------------------------------------------------------
    1. é€é Google API è£œä¸Š place_id
    """
    # ------------------------------------------------------------
    # å–å¾— place_id
    # ------------------------------------------------------------
    print(api_key)
    place_ids = []
    for _, row in df.iterrows():
        query = f"{row['name']} {row['address']}"
        print(Fore.GREEN + f"âœ… place_id{_} has been found.")
        place_ids.append(gm.get_place_id(api_key, query))
    # æœªé¿å…place_idé•·åº¦èˆ‡dfä¸åŒï¼Œå…ˆå‰µå»ºæ¬„ä½å¾Œå†å¡«å…¥è³‡æ–™
    df["place_id"] = np.nan
    df.loc[:, "place_id"] = place_ids
    df_filtered = df.dropna(subset="place_id")
    # å„²å­˜googleçˆ¬ä¸‹ä¾†å«æœ‰place_idçš„æª”æ¡ˆ
    sd.store_to_csv_no_index(df_filtered, save_path)
    return df_filtered


def gdata_info(df: pd.DataFrame, api_key: str, save_path: str):
    """
    1. é€é Google API è£œä¸Šè©³ç´°è³‡è¨Š
    2. ç¯©é¸å‡ºç‡Ÿæ¥­ä¸­çš„å•†å®¶ (business_status == "OPERATIONAL")
    3. æ•´ç†æ¬„ä½é †åºã€è£œç©ºå€¼ä¸¦å„²å­˜è³‡æ–™
    """
    # ------------------------------------------------------------
    # å–å¾— Google Maps è©³ç´°è³‡æ–™
    # ------------------------------------------------------------
    detailed_results = [
        gm.gmap_info(row["name"], api_key, row["place_id"]) for _, row in df.iterrows()
    ]
    df_checked = pd.DataFrame(detailed_results).dropna(subset=["place_id"])
    print(Fore.GREEN + "âœ… Google details have been found.")

    # ------------------------------------------------------------
    # åˆä½µåŸå§‹è³‡æ–™èˆ‡ Google API è©³ç´°è³‡æ–™
    # ------------------------------------------------------------
    df_merged = df.merge(
        df_checked,
        on="place_id",
        how="outer",
        suffixes=("_filtered", "_checked"),
    )
    # å„²å­˜googleçˆ¬ä¸‹ä¾†å«æœ‰è©³ç´°è³‡æ–™çš„æª”æ¡ˆ
    sd.store_to_csv_no_index(df_merged, save_path)
    return df_merged


def clean_sort(df: pd.DataFrame, save_path: str):
    """business_statusç‚ºç‡Ÿæ¥­ä¸­ï¼Œæ•´ç†æ¬„ä½åç¨±èˆ‡è£œç©ºå€¼

    Args:
        df (pd.DataFrame): å–çš„googleè©³ç´°è³‡æ–™çš„df
        save_path (str): å„²å­˜è·¯å¾‘

    Returns:
        _type_: æ•´ç†å¾Œçš„df
    """
    # ä¿ç•™ç‡Ÿæ¥­ä¸­çš„æ—…é¤¨
    df_merged = df[df["business_status"] == "OPERATIONAL"]
    print(Fore.GREEN + "âœ… Successfully merged the original data with the google data.")

    # ------------------------------------------------------------
    # æ¸…ç†èˆ‡æ•´ç†æ¬„ä½
    # ------------------------------------------------------------

    # å¦‚æœæœ‰ key_0ï¼Œæ”¹å› place_id
    if "key_0" in df_merged.columns and "place_id" not in df_merged.columns:
        df_merged.rename(columns={"key_0": "place_id"}, inplace=True)

    # å¡«è£œç©ºå€¼
    fillna_columns = ["opening_hours", "rating", "rating_total"]
    df_merged[fillna_columns] = df_merged[fillna_columns].fillna(0)
    print(Fore.GREEN + "âœ… Columns have been sorted and fill the missing value.")

    # ä¿®æ”¹columnsé †åº
    revised_columns = [
        "place_id",
        "name_checked",
        "address_checked",
        "phone",
        "city",
        "district",
        "business_status",
        "opening_hours",
        "rating",
        "rating_total",
        "longitude",
        "latitude",
        "map_url",
        "website",
        "newest_review",
    ]
    df_merged = df_merged[revised_columns].drop_duplicates(subset=["place_id"])

    # ------------------------------------------------------------
    # ä¿®æ”¹opening_hoursæ¬„ä½
    # ------------------------------------------------------------
    # csvè®€é€²ä¾†æ™‚listæœƒè¢«è½‰æˆå­—ä¸²ï¼Œæ‰€ä»¥å…ˆå°‡strè½‰æˆlist
    # df_merged["opening_hours"] = df_merged["opening_hours"].apply(str_to_list)
    df_merged.loc[:, "opening_hours"] = df_merged["opening_hours"].apply(
        dm.trans_op_time_to_hours
    )

    # ------------------------------------------------------------
    # è½‰æ›pdç©ºå€¼
    # ------------------------------------------------------------
    for col in df_merged.columns:
        df_merged[col] = df_merged[col].apply(to_sql_null)

    # # typesæ¬„ä½è§£é–‹list
    # df_merged.loc[:, "types"] = df_merged["types"].apply(
    #     lambda x: ",".join(x) if isinstance(x, list) else ""
    # )

    # å„²å­˜ä¿®æ”¹å¾Œçš„æª”æ¡ˆ
    sd.store_to_csv_no_index(df_merged, save_path)

    return df_merged


def merge_loc(
    df: pd.DataFrame,
    host: str,
    port: int,
    user: str,
    password: str,
    db: str,
    save_path: str,
) -> pd.DataFrame:
    """è®€å–DBä¸­çš„locationè¡¨ä¸¦åˆä½µ

    Args:
        df (pd.DataFrame): ç¶“égoogle dataåˆä½µçš„df
        host (str): ä¸»æ©Ÿåç¨±
        port (int): portè™Ÿ
        user (str): ä½¿ç”¨è€…åç¨±
        password (str): ä½¿ç”¨è€…å¯†ç¢¼
        db (str): è³‡æ–™åº«åç¨±
        save_path (str): å„²å­˜è·¯å¾‘
    Returns:
        pd.DataFrame: åˆä½µlocationå¾Œçš„df
    """
    # ------------------------------------------------------------
    # å¾è³‡æ–™åº«è®€å– location è¡¨æ ¼
    # ------------------------------------------------------------

    # é€£ç·šDB
    conn, cursor = connDB.connect_db(host, port, user, password, db)
    df_loc = connDB.get_loc_table(conn, cursor)
    # cursor.close()
    # conn.close()
    print(Fore.GREEN + "âœ… Cursor and connection have been closed.")

    # ------------------------------------------------------------
    # èˆ‡ location è¡¨æ ¼åˆä½µ (åŠ å…¥ loc_id)
    # ------------------------------------------------------------
    df_final = df.merge(
        df_loc, left_on=["city", "district"], right_on=["city", "district"], how="inner"
    )
    # ä¾ç…§cityå’Œdistrictæ’åº
    df_final = df_final.sort_values(["city", "district"])
    print(Fore.GREEN + "âœ… Location table has been merged with the original data.")

    # å„²å­˜ä¿®æ”¹å¾Œçš„æª”æ¡ˆ
    sd.store_to_csv_no_index(df_final, save_path)
    return df_final


def create_id(df: pd.DataFrame, id_sign: str, save_path: str) -> pd.DataFrame:
    """ç”¢ç”Ÿidè™Ÿç¢¼

    Args:
        df (pd.DataFrame): ç¶“élocationè¡¨æ ¼åˆä½µçš„df
        id_sign (str): idé–‹é ­æ–‡å­—
        save_path (str): å„²å­˜è·¯å¾‘

    Returns:
        pd.DataFrame: å«æœ‰idæ¬„ä½çš„df
    """
    # ------------------------------------------------------------
    # ç”¢ç”Ÿ idï¼ˆä¾‹å¦‚ï¼šht0001, ht0002...ï¼‰
    # ------------------------------------------------------------
    # çµ±ä¸€å°->è‡º
    df["city"] = df["city"].str.replace("å°", "è‡º")
    # æ’åº
    df = df.sort_values(["city", "district"])
    df["id"] = np.nan
    num_id = df["id"].isna().sum()
    new_ids = [f"{id_sign}{str(i).zfill(4)}" for i in range(1, num_id + 1)]
    df.loc[:, "id"] = new_ids
    print(Fore.GREEN + "âœ… id column has been serialized.")
    sd.store_to_csv_no_index(df, save_path)

    return df


def cat_id(
    df: pd.DataFrame,
    host: str,
    port: int,
    user: str,
    password: str,
    db: str,
    save_path: str,
    category: str,
) -> pd.DataFrame:
    # é€£ç·šDB
    conn, cursor = connDB.connect_db(host, port, user, password, db)
    # è®€å–categoryè¡¨æ ¼çš„è³‡æ–™
    sql = f"""
    select category_id
    from category
    where category_eng = '{category}';
    """
    cursor.execute(sql)
    cat = cursor.fetchall()
    cursor.close()
    conn.close()
    print(Fore.GREEN + "âœ… Cursor and connection have been closed.")

    # è½‰æˆdf
    df_cat = pd.DataFrame(data=cat, columns=["category_id"])

    # åŸæœ¬çš„dfå‰µç«‹ä¸€å€‹cat_idä¸¦è³¦å€¼
    df["cat_id"] = df_cat["category_id"].iloc[0]

    if category == "hospital":
        # åˆ¤æ–·168å°æ™‚é†«é™¢ä¸¦å°‡cat_idè®Šæˆ7
        df.loc[df["opening_hours"] == 168, "cat_id"] = 7

    # èª¿æ•´æ¬„ä½
    columns = [
        "id",
        "place_id",
        "name_checked",
        "address_checked",
        "phone",
        "city",
        "district",
        "loc_id",
        "business_status",
        "opening_hours",
        "cat_id",
        "rating",
        "rating_total",
        "longitude",
        "latitude",
        "map_url",
        "website",
        "newest_review",
    ]
    df = df[columns]
    sd.store_to_csv_no_index(df, save_path)

    return df


def to_sql_data(df: pd.DataFrame, save_path: str):
    """èª¿æ•´æ¬„ä½é †åºèˆ‡å„²å­˜æœ€çµ‚æª”æ¡ˆ

    Args:
        df (pd.DataFrame): å«æœ‰idçš„dfï¼Œè«‹ç¢ºèªopening_houræ¬„ä½å·²æ”¹æˆæ•¸å­—ä¸”ç©ºå€¼å·²è½‰æ›
        save_path (str): å„²å­˜è·¯å¾‘

    Returns:
        _type_: å¯ä»¥å¯«å…¥DBçš„df
    """
    # ------------------------------------------------------------
    # èª¿æ•´æ¬„ä½é †åºèˆ‡åç¨±
    # ------------------------------------------------------------
    final_columns = [
        "id",
        "name_checked",
        "business_status",
        "loc_id",
        "address_checked",
        "phone",
        "opening_hours",
        "cat_id",
        "rating",
        "rating_total",
        "newest_review",
        "longitude",
        "latitude",
        "map_url",
        "website",
        "place_id",
    ]
    df_final = df[final_columns]
    print(Fore.GREEN + "âœ… Final table has finished.")

    # ------------------------------------------------------------
    # å°‡æœ€çµ‚çµæœå„²å­˜æˆcsvæª”
    # ------------------------------------------------------------
    sd.store_to_csv_no_index(df_final, save_path)

    return df_final


def str_to_list(x: str) -> list:
    """csvæª”è®€å–listé€²ä¾†æ™‚æœƒè‡ªå‹•è®Šæˆstringï¼Œæ­¤å‡½å¼å¯ä»¥å°‡å­—ä¸²è½‰ç‚ºlist

    Args:
        x (str): å­—ä¸²å‹æ…‹è³‡æ–™

    Returns:
        list: ç¶“éè™•ç†å¾Œçš„list
    """
    try:
        val = ast.literal_eval(x)

        # âœ… å¦‚æœè½‰å®Œæ˜¯ list ä¸”è£¡é¢ç¬¬ä¸€å€‹å…ƒç´ ä¹Ÿæ˜¯ list
        # è¡¨ç¤ºå¤–é¢å¤šåŒ…äº†ä¸€å±¤ï¼Œè¦å–ç¬¬ä¸€å±¤çš„å…§å®¹
        if isinstance(val, list) and len(val) == 1 and isinstance(val[0], list):
            return val[0]

        # âœ… æ­£å¸¸ list
        if isinstance(val, list):
            return val

        # ä¸æ˜¯ listï¼Œå°±åŒ…æˆ list
        return [val]

    except (ValueError, SyntaxError):
        return [x]


def to_phone(df: pd.DataFrame) -> pd.DataFrame:
    import re

    def fix_phone(x):
        if x is None or pd.isna(x):
            return None

        # æµ®é»æ•¸ï¼ˆé¿å…è¢« pandas ç•¶æˆç§‘å­¸è¨˜è™Ÿï¼‰
        if isinstance(x, float):
            x = str(int(x))

        s = str(x).strip().lower()

        if s in ("nan", "none", ""):
            return None

        # ç§»é™¤æ‰€æœ‰éæ•¸å­—ç¬¦è™Ÿ
        digits = re.sub(r"\D", "", s)

        if digits == "":
            return None

        # è™•ç† +886 æ‰‹æ©Ÿ
        if digits.startswith("886") and len(digits) >= 11:
            digits = "0" + digits[3:]

        # æ‰‹æ©Ÿæ ¼å¼ (09xxxxxxxx)
        if len(digits) == 10 and digits.startswith("09"):
            return digits

        # å¸‚è©±ï¼ˆ0 é–‹é ­ + 9â€“10 ç¢¼ï¼‰
        if digits.startswith("0") and len(digits) in (9, 10):
            return digits

        return None

    df["phone"] = df["phone"].apply(fix_phone)
    print(Fore.GREEN + "ğŸ“ é›»è©±æ¬„ä½å·²è½‰æ›å®Œæˆ")
    return df


def to_sql_null(x):
    """å°‡pandasçš„ç©ºå€¼è½‰ç‚ºPythonçš„None

    Args:
        x (_type_): å‚³å…¥çš„æ¬„ä½å€¼

    Returns:
        None: å°±æ˜¯None
    """
    if pd.isna(x):
        return None
    s = str(x).strip()

    if s.lower() in ("nan", "none", ""):
        return None
    return x
