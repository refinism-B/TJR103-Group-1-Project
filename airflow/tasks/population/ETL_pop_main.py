import os
import sys
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# === åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„ ===
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

# === æ­£ç¢º importï¼ˆä½ çš„ E_pop.py çš„çœŸæ­£å‡½å¼åç¨±ï¼‰ ===
from tasks.population.E_pop import fetch_population_data
from tasks.population.T_pop import transform
from tasks.population.L_pop import load

# === è¼‰å…¥ .env ===
load_dotenv(dotenv_path=os.path.join(PROJECT_ROOT, ".env"))


def get_engine():
    username = os.getenv("MYSQL_USERNAME")
    password = os.getenv("MYSQL_PASSWORD")
    target_ip = os.getenv("MYSQL_IP")
    target_port = os.getenv("MYSQL_PORT")
    db_name = os.getenv("MYSQL_DB_NAME")

    if not all([username, password, target_ip, target_port, db_name]):
        raise ValueError("âŒ .env è³‡è¨Šä¸å®Œæ•´ï¼Œè«‹ç¢ºèª MySQL é€£ç·šåƒæ•¸")

    return create_engine(f"mysql+pymysql://{username}:{password}@{target_ip}:{target_port}/{db_name}")


def save_to_local(df, raw_path, processed_path):
    os.makedirs(os.path.dirname(raw_path), exist_ok=True)
    os.makedirs(os.path.dirname(processed_path), exist_ok=True)

    df.to_csv(raw_path, index=False, encoding="utf-8-sig")
    print(f"ğŸ“¦ [L1] å·²æˆåŠŸè¼¸å‡ºåŸå§‹è³‡æ–™ï¼š{raw_path}")

    df.to_csv(processed_path, index=False, encoding="utf-8-sig")
    print(f"ğŸ“¦ [L1] å·²æˆåŠŸè¼¸å‡ºè™•ç†å¾Œè³‡æ–™ï¼š{processed_path}")


def save_to_db(df, table_name):
    try:
        engine = get_engine()
        with engine.begin() as conn:
            conn.execute(text(f"CREATE TABLE IF NOT EXISTS {table_name} LIKE population;"))
            conn.execute(text(f"TRUNCATE TABLE {table_name}"))
            df.to_sql(table_name, con=conn, if_exists="append", index=False)

        print(f"ğŸ’¾ [L2] å·²æˆåŠŸåŒ¯å…¥ MySQL è³‡æ–™è¡¨ï¼š{table_name}")

    except Exception as e:
        print(f"âŒ åŒ¯å…¥ MySQL å¤±æ•—ï¼š{e}")


def load(df):
    base_dir = os.path.join(PROJECT_ROOT, "airflow", "data")
    raw_path = os.path.join(base_dir, "raw", "population", "population_raw.csv")
    processed_path = os.path.join(base_dir, "processed", "population", "population_processed.csv")
    table_name = "population_new"

    with ThreadPoolExecutor(max_workers=2) as executor:
        executor.submit(save_to_local, df, raw_path, processed_path)
        executor.submit(save_to_db, df, table_name)


def main():
    print("ğŸ“Š [E] Extract - æŠ“å–å…§æ”¿éƒ¨äººå£çµ±è¨ˆè³‡æ–™ä¸­...")

    # â­ è¨­å®šä¸‹è¼‰è³‡æ–™å¤¾ï¼šairflow/data/raw/population
    raw_dir = os.path.join(PROJECT_ROOT, "airflow", "data", "raw", "population")
    os.makedirs(raw_dir, exist_ok=True)

    # â­ æ­£ç¢ºå‘¼å« Extract å‡½å¼
    xls_path, year, month = fetch_population_data(raw_dir)

    print(f"ğŸ“„ æœ€æ–°ä¸‹è¼‰æª”æ¡ˆï¼š{xls_path}")
    print(f"ğŸ“… è³‡æ–™å¹´æœˆï¼š{year}/{month}")

    print("âš™ï¸ [T] Transform - æ¸…ç†èˆ‡æ•´åˆè³‡æ–™ä¸­...")

    # â­ read excel å†é€² Transform
    df_raw = pd.read_excel(xls_path, header=1)
    # åˆªé™¤å…¨éƒ¨ Unnamed æ¬„ä½
    df_raw = df_raw.loc[:, ~df_raw.columns.str.contains("Unnamed")]

    df_processed = transform(df_raw)

    print("ğŸ’¾ [L] Load - åœ°ç«¯å­˜æª”èˆ‡ DB åŒ¯å…¥ï¼ˆå¹³è¡Œé€²è¡Œï¼‰ä¸­...")
    load(df_processed)

    print("ğŸ‰ ETL Population Pipeline å®Œæˆï¼")


if __name__ == "__main__":
    main()
