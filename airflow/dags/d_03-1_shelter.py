import sys
import os
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator

# === ðŸ§© è¨­å®šæ¨¡çµ„æœå°‹è·¯å¾‘ (for tasks/shelter modules) ===
current_dir = os.path.dirname(os.path.abspath(__file__))          # /opt/airflow/dags
project_root = os.path.dirname(current_dir)                       # /opt/airflow
sys.path.append(os.path.join(project_root, "tasks", "shelter"))   # /opt/airflow/tasks/shelter

# === ðŸ§© åŒ¯å…¥è‡ªè¨‚æ¨¡çµ„ ===
from E_shelter import fetch_raw_data
from T_shelter import transform
from L_shelter import load

# === âš™ï¸ DAG é è¨­åƒæ•¸ ===
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# === ðŸ—“ï¸ å®šç¾© DAG ===
with DAG(
    dag_id='d_03-1_shelter',
    default_args=default_args,
    description='ETL pipeline for Taiwan shelter data',
    schedule=None,  # Airflow 3.x æ–°åƒæ•¸ï¼ˆå–ä»£ schedule_intervalï¼‰
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['517', 'shelter', 'monthly'],
) as dag:

    # === ðŸ¾ Extract ä»»å‹™ ===
    def extract_task():
        print("ðŸ¾ [E] Extract - æŠ“å–è¾²æ¥­éƒ¨è³‡æ–™ä¸­...")
        df_raw = fetch_raw_data()
        raw_dir = "/opt/airflow/data/raw"
        os.makedirs(raw_dir, exist_ok=True)
        df_raw.to_csv(f"{raw_dir}/shelter_raw.csv", index=False)
        print(f"âœ… Extract å®Œæˆï¼Œå…± {len(df_raw)} ç­†è³‡æ–™ï¼")
        return "extract done"

    # === âš™ï¸ Transform ä»»å‹™ ===
    def transform_task():
        print("âš™ï¸ [T] Transform - æ¸…ç†èˆ‡ Google è³‡æ–™æ•´åˆä¸­...")
        import pandas as pd
        raw_path = "/opt/airflow/data/raw/shelter_raw.csv"
        processed_dir = "/opt/airflow/data/processed"
        os.makedirs(processed_dir, exist_ok=True)

        df_raw = pd.read_csv(raw_path)
        df_processed = transform(df_raw)
        df_processed.to_csv(f"{processed_dir}/shelter_processed.csv", index=False)

        print(f"âœ… Transform å®Œæˆï¼Œè¼¸å‡º {len(df_processed)} ç­†è³‡æ–™ï¼")
        return "transform done"

    # === ðŸ’¾ Load ä»»å‹™ ===
    def load_task():
        print("ðŸ’¾ [L] Load - åŒ¯å…¥ MySQL ä¸­...")
        import pandas as pd
        processed_path = "/opt/airflow/data/processed/shelter_processed.csv"
        df_processed = pd.read_csv(processed_path)
        load(df_processed)
        print("ðŸŽ‰ ETL Shelter Pipeline å…¨éƒ¨å®Œæˆï¼")
        return "load done"

    # === å®šç¾©ä¸‰å€‹ä»»å‹™ ===
    t1 = PythonOperator(task_id='extract', python_callable=extract_task)
    t2 = PythonOperator(task_id='transform', python_callable=transform_task)
    t3 = PythonOperator(task_id='load', python_callable=load_task)

    # === DAG æµç¨‹é †åº ===
    t1 >> t2 >> t3
