import sys
import os
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator

# === ðŸ§© è¨­å®šæ¨¡çµ„æœå°‹è·¯å¾‘ (for tasks/population modules) ===
current_dir = os.path.dirname(os.path.abspath(__file__))          # /opt/airflow/dags
project_root = os.path.dirname(current_dir)                       # /opt/airflow
sys.path.append(os.path.join(project_root, "tasks", "population"))  # /opt/airflow/tasks/population

# === ðŸ§© åŒ¯å…¥è‡ªè¨‚æ¨¡çµ„ ===
# ç¢ºèªä½ æœ‰ tasks/population/E_pop.py ä¸¦åŒ…å«å¿…è¦çš„å‡½å¼
from E_pop import fetch_raw_data
from T_pop import transform
from L_pop import load

# === âš™ï¸ DAG é è¨­åƒæ•¸ ===
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# === ðŸ—“ï¸ å®šç¾© DAG ===
with DAG(
    dag_id='d_03-2_population',
    default_args=default_args,
    description='ETL pipeline for Taiwan population data',
    schedule=None,  # Airflow 3.x æ–°å¯«æ³•
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=['517', 'population', 'monthly'],
) as dag:

    # === ðŸ§® Extract ä»»å‹™ ===
    def extract_task():
        print("ðŸ“Š [E] Extract - æŠ“å–å…§æ”¿éƒ¨äººå£çµ±è¨ˆè³‡æ–™ä¸­...")
        df_raw = fetch_raw_data()
        raw_dir = "/opt/airflow/data/raw"
        os.makedirs(raw_dir, exist_ok=True)
        df_raw.to_csv(f"{raw_dir}/population_raw.csv", index=False)
        print(f"âœ… Extract å®Œæˆï¼Œå…± {len(df_raw)} ç­†è³‡æ–™ï¼")
        return "extract done"

    # === ðŸ§¹ Transform ä»»å‹™ ===
    def transform_task():
        print("âš™ï¸ [T] Transform - æ•´ç†äººå£çµ±è¨ˆè³‡æ–™ä¸­...")
        import pandas as pd
        raw_path = "/opt/airflow/data/raw/population_raw.csv"
        processed_dir = "/opt/airflow/data/processed"
        os.makedirs(processed_dir, exist_ok=True)

        df_raw = pd.read_csv(raw_path)
        df_processed = transform(df_raw)
        df_processed.to_csv(f"{processed_dir}/population_processed.csv", index=False)

        print(f"âœ… Transform å®Œæˆï¼Œè¼¸å‡º {len(df_processed)} ç­†è³‡æ–™ï¼")
        return "transform done"

    # === ðŸ’¾ Load ä»»å‹™ ===
    def load_task():
        print("ðŸ’¾ [L] Load - åŒ¯å…¥ MySQL ä¸­...")
        import pandas as pd
        processed_path = "/opt/airflow/data/processed/population_processed.csv"
        df_processed = pd.read_csv(processed_path)
        load(df_processed)
        print("ðŸŽ‰ ETL Population Pipeline å…¨éƒ¨å®Œæˆï¼")
        return "load done"

    # === DAG ä»»å‹™é †åº ===
    t1 = PythonOperator(task_id='extract', python_callable=extract_task)
    t2 = PythonOperator(task_id='transform', python_callable=transform_task)
    t3 = PythonOperator(task_id='load', python_callable=load_task)

    t1 >> t2 >> t3
