import os
import requests
import pandas as pd
from time import sleep
from datetime import datetime

GOOGLE_API_KEY = "AIzaSyAKD_bSB7Z26zBK1JN2yVdTXOxDNEfznQo"
PLACES_URL = "https://maps.googleapis.com/maps/api/place/textsearch/json"
DETAILS_URL = "https://maps.googleapis.com/maps/api/place/details/json"

cities = ["å°åŒ—å¸‚", "æ–°åŒ—å¸‚", "æ¡ƒåœ’å¸‚", "å°ä¸­å¸‚", "å°å—å¸‚", "é«˜é›„å¸‚"]
query_template = "{} å¯µç‰©ç¾å®¹"
all_data = []

def search_places(query):
    results = []
    params = {
        "query": query,
        "key": GOOGLE_API_KEY,
        "language": "zh-TW"
    }
    while True:
        res = requests.get(PLACES_URL, params=params)
        data = res.json()
        results.extend(data.get("results", []))
        next_page_token = data.get("next_page_token")
        if not next_page_token:
            break
        sleep(2)
        params["pagetoken"] = next_page_token
    return results

def get_place_details(place_id):
    params = {
        "place_id": place_id,
        "fields": "name,formatted_address,rating,user_ratings_total,business_status,url,formatted_phone_number,opening_hours,reviews",
        "key": GOOGLE_API_KEY,
        "language": "zh-TW"
    }
    res = requests.get(DETAILS_URL, params=params)
    return res.json().get("result", {})

def extract_district(address):
    for part in address.split():
        if any(kw in part for kw in ["å€", "é®", "é„‰"]):
            return part
    return None

def parse_opening_hours(opening_hours_str):
    if not opening_hours_str or pd.isna(opening_hours_str):
        return None
    total_hours = 0.0
    for day_info in opening_hours_str.split("; "):
        try:
            parts = day_info.split(": ")
            if len(parts) != 2:
                continue
            time_ranges = parts[1].split(", ")
            for time_range in time_ranges:
                if "ä¼‘æ¯" in time_range or "æœªç‡Ÿæ¥­" in time_range:
                    continue  # âœ… è·³éä¼‘æ¯æ—¥
                if "â€“" not in time_range:
                    continue  # âœ… è·³éç„¡æ³•è§£æçš„æ ¼å¼
                start_str, end_str = time_range.split("â€“")
                start = datetime.strptime(start_str.strip(), "%H:%M")
                end = datetime.strptime(end_str.strip(), "%H:%M")
                duration = (end - start).seconds / 3600
                total_hours += duration
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•è§£ææ™‚é–“æ®µï¼š{day_info} - {e}")
            continue
    return round(total_hours, 2)

def get_latest_review_time(reviews):
    timestamps = [r.get("time") for r in reviews if r.get("time")]
    if timestamps:
        return datetime.fromtimestamp(max(timestamps)).strftime("%Y-%m-%d")
    return None

for city in cities:
    print(f"ğŸ” æŸ¥è©¢ä¸­ï¼š{city}")
    query = query_template.format(city)
    places = search_places(query)

    for place in places:
        place_id = place.get("place_id")
        details = get_place_details(place_id)
        sleep(1)

        address = details.get("formatted_address", "")
        district = extract_district(address)
        phone = details.get("formatted_phone_number")
        hours = details.get("opening_hours", {}).get("weekday_text")
        hours_str = "; ".join(hours) if hours else None
        weekly_hours = parse_opening_hours(hours_str)
        latest_review = get_latest_review_time(details.get("reviews", []))

        status_map = {
            "OPERATIONAL": "ç‡Ÿæ¥­ä¸­",
            "CLOSED_TEMPORARILY": "æš«æ™‚é—œé–‰",
            "CLOSED_PERMANENTLY": "æ°¸ä¹…åœæ¥­"
        }

        all_data.append({
            "ç¸£å¸‚": city,
            "è¡Œæ”¿å€": district,
            "åº—å": details.get("name"),
            "åœ°å€": address,
            "é›»è©±": phone,
            "Google è©•åˆ†": details.get("rating"),
            "è©•åˆ†äººæ•¸": details.get("user_ratings_total"),
            "ç‡Ÿæ¥­ç‹€æ…‹": status_map.get(details.get("business_status")),
            "ç‡Ÿæ¥­æ™‚é–“": hours_str,
            "æ¯é€±ç‡Ÿæ¥­æ™‚æ•¸": weekly_hours,
            "æœ€æ–°è©•è«–æ—¥æœŸ": latest_review,
            "GMap ç¶²å€": details.get("url")
        })

# å„²å­˜åˆ° data è³‡æ–™å¤¾
data_dir = os.path.join(os.getcwd(), "data")
os.makedirs(data_dir, exist_ok=True)
output_path = os.path.join(data_dir, "six_city_pet_grooming_google.csv")

df = pd.DataFrame(all_data)
df.to_csv(output_path, index=False, encoding="utf-8-sig")
print(f"âœ… å·²å„²å­˜è‡³ï¼š{output_path}")