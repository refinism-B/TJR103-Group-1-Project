import os
import requests
import pandas as pd
import urllib3
import platform
import subprocess
import re
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

from dotenv import load_dotenv
load_dotenv(dotenv_path=os.path.join(os.getcwd(), ".env"))
from sqlalchemy import create_engine

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

GOOGLE_API_KEY = "AIzaSyAKD_bSB7Z26zBK1JN2yVdTXOxDNEfznQo"
GOOGLE_PLACES_SEARCH_URL = "https://maps.googleapis.com/maps/api/place/textsearch/json"
GOOGLE_PLACES_DETAILS_URL = "https://maps.googleapis.com/maps/api/place/details/json"
API_LINK = "https://data.moa.gov.tw/Service/OpenData/TransService.aspx?UnitId=2thVboChxuKs"

data_dir = os.path.join(os.getcwd(), "data")
os.makedirs(data_dir, exist_ok=True)
output_file = os.path.join(data_dir, "taiwan_pet_shelters_with_google.csv")

def get_api_json(url: str):
    res = requests.get(url, verify=False, timeout=15)
    res.raise_for_status()
    return res.json()

def clean_address(address):
    if pd.isna(address):
        return address
    address = re.sub(r"^\d{3,5}", "", address).strip()
    address = re.sub(r"[\(ï¼ˆ][^\)ï¼‰]*[\)ï¼‰]", "", address)
    return address.strip()

def get_place_info(name, address):
    query = f"{name} {address}"
    params = {"query": query, "key": GOOGLE_API_KEY, "language": "zh-TW"}
    res = requests.get(GOOGLE_PLACES_SEARCH_URL, params=params, timeout=10)
    data = res.json()
    if data.get("results"):
        result = data["results"][0]
        return {
            "place_id": result.get("place_id"),
            "lat": result["geometry"]["location"]["lat"],
            "lng": result["geometry"]["location"]["lng"]
        }
    return None

def get_place_details(place_id):
    params = {
        "place_id": place_id,
        "fields": "rating,user_ratings_total,opening_hours,current_opening_hours,reviews,url,business_status",
        "language": "zh-TW",
        "key": GOOGLE_API_KEY,
    }
    res = requests.get(GOOGLE_PLACES_DETAILS_URL, params=params, timeout=10)
    data = res.json()
    result = data.get("result", {})

    opening_hours = None
    if result.get("opening_hours") and "weekday_text" in result["opening_hours"]:
        opening_hours = "; ".join(result["opening_hours"]["weekday_text"])

    # âœ… æ”¹ç”¨ business_status
    business_status_map = {
        "OPERATIONAL": "ç‡Ÿæ¥­ä¸­",
        "CLOSED_TEMPORARILY": "æš«æ™‚é—œé–‰",
        "CLOSED_PERMANENTLY": "æ°¸ä¹…åœæ¥­"
    }
    business_status = business_status_map.get(result.get("business_status"), None)

    latest_review_time = None
    if result.get("reviews"):
        timestamps = [r.get("time") for r in result["reviews"] if r.get("time")]
        if timestamps:
            latest_review_time = datetime.fromtimestamp(max(timestamps)).strftime("%Y-%m-%d")

    gmap_url = result.get("url")

    return {
        "rating": result.get("rating"),
        "user_ratings_total": result.get("user_ratings_total"),
        "opening_hours": opening_hours,
        "business_status": business_status,
        "latest_review_time": latest_review_time,
        "gmap_url": gmap_url
    }

def parse_opening_hours(opening_hours_str):
    if not opening_hours_str or pd.isna(opening_hours_str):
        return None
    total_hours = 0.0
    for day_info in opening_hours_str.split("; "):
        try:
            # ç¯„ä¾‹: "æ˜ŸæœŸä¸€: ä¼‘æ¯" æˆ– "æ˜ŸæœŸäºŒ: 10:00â€“12:00, 14:00â€“16:00"
            parts = day_info.split(": ")
            if len(parts) != 2:
                continue

            day_label, time_part = parts[0], parts[1]

            # âœ… è‹¥åŒ…å«ä¼‘æ¯ã€æœªç‡Ÿæ¥­ã€ç„¡è³‡æ–™å‰‡ç•¥é
            if any(kw in time_part for kw in ["ä¼‘æ¯", "æœªç‡Ÿæ¥­", "å…¬ä¼‘", "ä¸ç‡Ÿæ¥­"]):
                continue

            # âœ… ç¢ºä¿æ™‚é–“å€æ®µæœ‰ "â€“"
            time_ranges = [r.strip() for r in time_part.split(",") if "â€“" in r]
            for time_range in time_ranges:
                try:
                    start_str, end_str = [t.strip() for t in time_range.split("â€“")]
                    start = datetime.strptime(start_str, "%H:%M")
                    end = datetime.strptime(end_str, "%H:%M")

                    # è‹¥è·¨åˆå¤œï¼Œè£œä¸€å¤©
                    if end < start:
                        end = end.replace(day=start.day + 1)

                    duration = (end - start).seconds / 3600
                    total_hours += duration
                except Exception as inner_e:
                    print(f"âš ï¸ ç„¡æ³•è§£ææ™‚é–“æ®µï¼š{day_info} - {inner_e}")
                    continue
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•è§£ææ™‚é–“æ®µï¼š{day_info} - {e}")
            continue

    return round(total_hours, 2)


def enrich_with_google_info(row):
    name, addr = row["æ”¶å®¹æ‰€åç¨±"], row["åœ°å€"]
    try:
        place_info = get_place_info(name, addr)
        if not place_info:
            print(f"âš ï¸ æ‰¾ä¸åˆ° {name} çš„ Google è³‡æ–™")
            return {
                "Google è©•åˆ†": None,
                "è©•åˆ†äººæ•¸": None,
                "ç‡Ÿæ¥­æ™‚é–“": None,
                "Place ID": None,
                "ç¶“åº¦": None,
                "ç·¯åº¦": None,
                "ç‡Ÿæ¥­ç‹€æ…‹": None,
                "æœ€æ–°è©•è«–æ—¥æœŸ": None,
                "GMap ç¶²å€": None
            }

        details = get_place_details(place_info["place_id"])
        print(f"âœ… {name} â†’ {details['rating']}â­ ({details['user_ratings_total']} å‰‡)")
        return {
            "Google è©•åˆ†": details["rating"],
            "è©•åˆ†äººæ•¸": details["user_ratings_total"],
            "ç‡Ÿæ¥­æ™‚é–“": details["opening_hours"],
            "Place ID": place_info["place_id"],
            "ç¶“åº¦": place_info["lng"],
            "ç·¯åº¦": place_info["lat"],
            "ç‡Ÿæ¥­ç‹€æ…‹": details["business_status"],  # âœ… æ”¹é€™è£¡
            "æœ€æ–°è©•è«–æ—¥æœŸ": details["latest_review_time"],
            "GMap ç¶²å€": details["gmap_url"]
        }
    except Exception as e:
        print(f"âš ï¸ æŸ¥è©¢å¤±æ•—ï¼š{name} ({addr}) - {e}")
        return {
            "Google è©•åˆ†": None,
            "è©•åˆ†äººæ•¸": None,
            "ç‡Ÿæ¥­æ™‚é–“": None,
            "Place ID": None,
            "ç¶“åº¦": None,
            "ç·¯åº¦": None,
            "ç‡Ÿæ¥­ç‹€æ…‹": None,
            "æœ€æ–°è©•è«–æ—¥æœŸ": None,
            "GMap ç¶²å€": None
        }

def override_with_adoption_info(row):
    name = row["æ”¶å®¹æ‰€åç¨±"]
    if "è‹—æ —" in name and "æ”¶å®¹æ‰€" in name:
        opening_hours = "; ".join([
            "æ˜ŸæœŸä¸€: ä¼‘æ¯",
            "æ˜ŸæœŸäºŒ: 10:00â€“12:00, 13:00â€“16:00",
            "æ˜ŸæœŸä¸‰: 10:00â€“12:00, 13:00â€“16:00",
            "æ˜ŸæœŸå››: 10:00â€“12:00, 13:00â€“16:00",
            "æ˜ŸæœŸäº”: 10:00â€“12:00, 13:00â€“16:00",
            "æ˜ŸæœŸå…­: 10:00â€“12:00, 13:00â€“16:00",
            "æ˜ŸæœŸæ—¥: ä¼‘æ¯"
        ])
        return opening_hours, 25.0
    elif "ç‘èŠ³" in name:
        opening_hours = "; ".join([
            "æ˜ŸæœŸä¸€: 10:00â€“12:00, 14:00â€“16:00",
            "æ˜ŸæœŸäºŒ: 10:00â€“12:00, 14:00â€“16:00",
            "æ˜ŸæœŸä¸‰: 10:00â€“12:00, 14:00â€“16:00",
            "æ˜ŸæœŸå››: 10:00â€“12:00, 14:00â€“16:00",
            "æ˜ŸæœŸäº”: 10:00â€“12:00, 14:00â€“16:00",
            "æ˜ŸæœŸå…­: ä¼‘æ¯",
            "æ˜ŸæœŸæ—¥: ä¼‘æ¯"
        ])
        return opening_hours, 20.0
    return row["ç‡Ÿæ¥­æ™‚é–“"], row["æ¯é€±ç‡Ÿæ¥­æ™‚æ•¸"]

def open_file(filepath):
    system = platform.system()
    try:
        if system == "Windows":
            os.startfile(filepath)
        elif system == "Darwin":
            subprocess.call(["open", filepath])
        elif system == "Linux":
            subprocess.call(["xdg-open", filepath])
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•è‡ªå‹•é–‹å•Ÿæª”æ¡ˆï¼š{e}")

def main():
    print("ğŸ¾ æ­£åœ¨å¾è¾²æ¥­éƒ¨ API æŠ“å–è³‡æ–™...")
    data = get_api_json(API_LINK)
    df = pd.DataFrame(data)
    print(f"ğŸ“‹ å…±å–å¾— {len(df)} ç­†å…¨å°æ”¶å®¹æ‰€è³‡æ–™")

    df = df[["ShelterName", "CityName", "Address", "Phone"]].copy()
    df.rename(columns={
        "ShelterName": "æ”¶å®¹æ‰€åç¨±",
        "CityName": "ç¸£å¸‚",
        "Address": "åœ°å€",
        "Phone": "é›»è©±",
    }, inplace=True)

    print("ğŸ” æŸ¥è©¢ Google Maps è©•åˆ†ã€è©•è«–äººæ•¸èˆ‡ç‡Ÿæ¥­æ™‚é–“ä¸­ï¼ˆå¤šåŸ·è¡Œç·’ï¼‰...")
    with ThreadPoolExecutor(max_workers=6) as executor:
        futures = {executor.submit(enrich_with_google_info, row): idx for idx, row in df.iterrows()}
        results = {}
        for future in as_completed(futures):
            idx = futures[future]
            results[idx] = future.result()

    result_df = pd.DataFrame.from_dict(results, orient="index")
    df = pd.concat([df, result_df], axis=1)

    print("ğŸ§¹ æ¸…ç†åœ°å€æ ¼å¼ä¸­...")
    df["åœ°å€"] = df["åœ°å€"].apply(clean_address)

    print("â±ï¸ è¨ˆç®—æ¯é€±ç‡Ÿæ¥­æ™‚æ•¸ä¸­...")
    df["æ¯é€±ç‡Ÿæ¥­æ™‚æ•¸"] = df["ç‡Ÿæ¥­æ™‚é–“"].apply(parse_opening_hours)

    print("ğŸ“Œ å¥—ç”¨å‹•ç‰©ä¿è­·è³‡è¨Šç¶²èªé ˜é¤Šæ™‚é–“...")
    df[["ç‡Ÿæ¥­æ™‚é–“", "æ¯é€±ç‡Ÿæ¥­æ™‚æ•¸"]] = df.apply(override_with_adoption_info, axis=1, result_type="expand")

    print("ğŸ†• å·²åŠ å…¥æ¬„ä½ï¼šç‡Ÿæ¥­ç‹€æ…‹ã€æœ€æ–°è©•è«–æ—¥æœŸã€GMap ç¶²å€")

    df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"ğŸ“Š å·²æˆåŠŸè¼¸å‡ºè‡³ï¼š{output_file}")
    print(f"âœ… å…± {len(df)} ç­†æ”¶å®¹æ‰€è³‡æ–™å·²å®Œæˆ")

    open_file(output_file)
    print("ğŸªŸ å·²è‡ªå‹•é–‹å•Ÿè¼¸å‡ºæª”æ¡ˆ")

    return df

if __name__ == "__main__":
    df = main()


# === å°‡è³‡æ–™å¯«å…¥ MySQL ===
username = os.getenv("MYSQL_USERNAME")
password = os.getenv("MYSQL_PASSWORD")
target_ip = os.getenv("MYSQL_IP")
target_port = int(os.getenv("MYSQL_PORTT"))
db_name = os.getenv("MYSQL_DB_NAME")

engine = create_engine(f"mysql+pymysql://{username}:{password}@{target_ip}:{target_port}/{db_name}")

try:
    df.to_sql(name="pet_shelter", con=engine, if_exists="replace", index=False)
    print("âœ… å·²æˆåŠŸåŒ¯å…¥è‡³ MySQL è³‡æ–™è¡¨ï¼špet_shelter")
except Exception as e:
    print(f"âŒ åŒ¯å…¥ MySQL å¤±æ•—ï¼š{e}")


