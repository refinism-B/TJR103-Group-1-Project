# TJR103 雲端資料工程師班 第一組專題：寵物資訊站

## 研究動機

本專題的研究動機是從自身的經驗（組員為飼主）出發，並嘗試解答幾個問題：

1. **站在飼主的角度**：在台灣的縣市中，哪裡的寵物資源最豐富？
2. **站在業者的角度**：在台灣的縣市中，哪個地區的寵物商業潛力更多？
3. 是否有可能建立一個**寵物資源匯集平台**？讓使用者能夠集中查詢相關的資源及資訊。

## 作法與策略

本專題有以下幾個前提框架：

1. **以六都為研究對象**：基於時間和資源考量，我們將目標放在六都，最小行政單位為「**區**」。六都是人口及資源最集中的區域，能最大化涵蓋可能的使用者。
2. **店家分類**：將店家分為「**寵物用品**」、「**寵物餐廳**」、「**寵物美容**」、「**寵物旅館**」、「**寵物醫院**」、「**寵物收容所**」等六大類，是目前最常見的寵物業店家。

專題大致分為下列幾個步驟：

1. **收集資料**：蒐集各地區的寵物店家資訊，以及各地區每日寵物登記數資料。
2. **分析評比**：根據公式計算出地區的便利性指標及商業潛力指標。便可量化比較。
3. **展示資訊**：將蒐集到的店家資訊，按照類別和地區分類，透過視覺化的方式呈現，讓使用者可以根據需要進行查詢。

## 專案介紹

### 資料來源
- 寵物登記數資料：來自[農業部寵物登記管理資訊網](https://www.pet.gov.tw/Web/O302.aspx)，為每日更新的寵物登記資料。
- 公立收容所資料：來自[動物保護資訊網](https://animal.moa.gov.tw/Frontend/PublicShelter)的收容所查詢資料。
- 人口、行政區面積資料：來自內政部戶政司。
- 寵物醫院資料：來自[農業部動植物防疫檢疫署](https://ahis9.aphia.gov.tw/Veter/OD/HLIndex.aspx)的全國獸醫師執業、診療機構開業查詢。
- 其他類店家資料：使用google map搜尋服務取得。

### 資料蒐集
- 主要使用python的爬蟲套件：**requests、beautifulsoup、selenium**等，自動化蒐集、更新資料。
- 店家資料則是透過google提供的google maps API資源，分成兩步驟搜尋：
    1. 使用「**nearby search***」的方式，搜尋六都範圍內的所有店家。
    2. 將步驟1取得的店家資訊去除重複值後，使用google map的**place API服務***進行精準查詢，蒐集店家的詳細資訊（包含營業時間、用戶評分、評論數、網址等）。
        >*「**nearby search**」讓使用者可以**設定一經緯度為中心，並搜尋半徑內符合關鍵字的地標**。首先需取得六都地理邊界資料（來自[內政部國土測繪中心](https://whgis-nlsc.moi.gov.tw/Opendata/Files.aspx)）並根據設定的搜尋半徑，計算出在範圍內的**所有經緯度座標點**。再透過程式自動化的、逐個座標點進行nearby search，並將搜尋到的地標記錄下來。
        >*在googla map中的地標都有一個唯一的id值「place id」，可透過place api進行準確查詢。
- 整個搜尋過程將大量使用google map查詢資源，且會產生相應的費用。但每次搜尋都會記錄使用情況，以便未來隨時調整搜尋設定控制成本。

### ETL
- 由於資料都是**結構化資料**，所以本專題ETL幾乎都以python的pandas為主要工具進行處理。
- 幾個重要的處理重點：
    1. 剔除不在六都範圍內的資料。
    2. 剔除地址或經緯度為空值的資料（無法定位）。
    3. 剔除**暫停營業**或**歇業**，或店家名稱明確表示**無法提供服務**的資料。
    4. 將營業時間轉換為**營業時數**（方便計算指標）。
    5. 將**市**及**區**的資料取出形成獨立欄位（用於分類）。

### 自動化data pipeline
- 設立**GCP雲端VM**作為24小時不間段運作主機。
- 在VM中建立**MySQL資料庫**，供組員可以查詢、存/讀資料。
- 在VM中建立**Airflow**自動化排程工具，為每一類資料建立一個dag，即為一條data pipeline。
- 同時啟用**GCS**及**BigQuery**服務，前者用於雲端存放資料檔案，後者則透過檔案建立SQL資料查詢。

### 指標計算與資料視覺化